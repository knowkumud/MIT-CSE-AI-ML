{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "020867cf-b9f3-40b8-beed-f27cdf618eef",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acf93170-ed0c-41e4-a70c-60d4e7ba0d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.7761, 0.5746, 0.4965, 0.4540, 0.2030, 0.5472],\n",
      "        [0.9234, 0.0995, 0.8705, 0.3629, 0.6596, 0.6208],\n",
      "        [0.8230, 0.6091, 0.1607, 0.3446, 0.9557, 0.9892],\n",
      "        [0.8359, 0.1438, 0.2813, 0.2297, 0.3188, 0.6237],\n",
      "        [0.3954, 0.1712, 0.2542, 0.2636, 0.6073, 0.9864],\n",
      "        [0.7626, 0.5949, 0.3403, 0.0079, 0.2547, 0.3905]])\n",
      "image.shape= torch.Size([1, 6, 6])\n",
      "image.shape= torch.Size([1, 1, 6, 6])\n",
      "image= tensor([[[[0.7761, 0.5746, 0.4965, 0.4540, 0.2030, 0.5472],\n",
      "          [0.9234, 0.0995, 0.8705, 0.3629, 0.6596, 0.6208],\n",
      "          [0.8230, 0.6091, 0.1607, 0.3446, 0.9557, 0.9892],\n",
      "          [0.8359, 0.1438, 0.2813, 0.2297, 0.3188, 0.6237],\n",
      "          [0.3954, 0.1712, 0.2542, 0.2636, 0.6073, 0.9864],\n",
      "          [0.7626, 0.5949, 0.3403, 0.0079, 0.2547, 0.3905]]]])\n",
      "kernel= tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "kernel size torch.Size([1, 1, 3, 3])\n",
      "outimage= torch.Size([1, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "image = torch.rand(6,6)\n",
    "print(\"image=\", image)\n",
    "#Add a new dimension along 0th dimension\n",
    "#i.e. (6,6) becomes (1,6,6). This is because\n",
    "#pytorch expects the input to conv2D as 4d tensor\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "print(\"image=\", image)\n",
    "kernel = torch.ones(3,3)\n",
    "#kernel = torch.rand(3,3)\n",
    "print(\"kernel=\", kernel)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "kernel = kernel.unsqueeze(dim=0)\n",
    "print(\"kernel size\",kernel.shape)\n",
    "#Perform the convolution\n",
    "outimage = F.conv2d(image, kernel, stride=1, padding=0)\n",
    "print(\"outimage=\", outimage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a02b255-5fea-4231-97b8-4bf0238000d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimage 2 size= torch.Size([1, 1, 2, 2])\n",
      "outimage 3 size= torch.Size([1, 1, 2, 2])\n",
      "outimage 4 = torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "outimage2 = F.conv2d(image, kernel, stride=2, padding=0)\n",
    "print(\"outimage 2 size=\", outimage2.shape)\n",
    "outimage3 = F.conv2d(image, kernel, stride=3, padding=0)\n",
    "print(\"outimage 3 size=\", outimage3.shape)\n",
    "outimage4 = F.conv2d(image, kernel, stride=4, padding=0)\n",
    "print(\"outimage 4 =\", outimage4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a412861-6522-4ef8-8a72-7b6a68deb160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimage 2 size= torch.Size([1, 1, 6, 6])\n",
      "outimage 3 size= torch.Size([1, 1, 8, 8])\n",
      "outimage 4 size= torch.Size([1, 1, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "outimage2 = F.conv2d(image, kernel, stride=1, padding=1)\n",
    "print(\"outimage 2 size=\", outimage2.shape)\n",
    "outimage3 = F.conv2d(image, kernel, stride=1, padding=2)\n",
    "print(\"outimage 3 size=\", outimage3.shape)\n",
    "outimage4 = F.conv2d(image, kernel, stride=1, padding=3)\n",
    "print(\"outimage 4 size=\", outimage4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f3d83-a42b-4472-af1b-232d08ebee34",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7751db16-40d0-4637-9100-b5cc5bb7fd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape= torch.Size([1, 1, 6, 6])\n",
      "outimage for functional conv2d= torch.Size([1, 3, 4, 4])\n",
      "outimage size for nn.conv2d= torch.Size([1, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand(6,6)\n",
    "#Add a new dimension along 0th dimension\n",
    "#i.e. (6,6) becomes (1,6,6). This is because\n",
    "#pytorch expects the input to conv2D as 4d tensor\n",
    "image = image.unsqueeze(dim=0)\n",
    "image = image.unsqueeze(dim=0)\n",
    "print(\"image.shape=\", image.shape)\n",
    "filters = torch.randn(3, 1, 3, 3)\n",
    "out = F.conv2d(image, filters, padding=0)\n",
    "print(\"outimage for functional conv2d=\", out.shape)\n",
    "out = torch.nn.Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
    "print(\"outimage size for nn.conv2d=\", out(image).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e4bd0-8a10-4dfe-a54d-c8fc0fe7027a",
   "metadata": {},
   "source": [
    "Q3 & Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "553a66d3-ec72-4420-b64f-3c6651c0a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34ff5cd0-b293-4a4b-9c79-e6572e8a08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b628a0e-c7d0-441a-a115-c81cc5e39c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f775ab7-aa19-4332-bd7a-cd11aa2a8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Conv2d(1,64,kernel_size=3, padding = 1),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(64,128,kernel_size=3, padding = 1),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(128,64,kernel_size=3, padding = 1),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2), stride = 2))\n",
    "        self.nn = nn.Sequential(nn.Linear(64,20,bias = True),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(20,10,bias = True))\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return self.nn(output.view(100,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "020de17b-c9bf-4d05-af90-7daf6bdddc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5a4d190-ceb7-4811-9f1c-1a53cccc95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6480160f-d677-40cf-a278-df3cfb50edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2906a40d-badd-4562-ba26-85919403e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a131ded-a676-41f5-aff7-32583914f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def trainModel(model, num_epochs,train_loader,optimizer):\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            # origin shape: [100, 1, 28, 28]\n",
    "            # resized: [100, 784]\n",
    "            # images = images.reshape(-1, 28*28).to(device)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if (i+1) % 100 == 0:\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6e59e0a-5682-4436-8fe6-7983e5dc119d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1702400440653/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/600], Loss: 0.2862\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3403\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2120\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0827\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1701\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2042\n"
     ]
    }
   ],
   "source": [
    "trainModel(model,1, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "371afa6d-555d-4212-883a-e67e1037a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Conv2d(1,32,kernel_size=3, padding = 1),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(32,64,kernel_size=3, padding = 1),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(64,32,kernel_size=3, padding = 1),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2), stride = 2))\n",
    "        self.nn = nn.Sequential(nn.Linear(32,20,bias = True),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(20,10,bias = True))\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return self.nn(output.view(100,-1))\n",
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Conv2d(1,16,kernel_size=3, padding = 1),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(16,32,kernel_size=3, padding = 1),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(32,16,kernel_size=3, padding = 1),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2), stride = 2))\n",
    "        self.nn = nn.Sequential(nn.Linear(16,20,bias = True),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(20,10,bias = True))\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return self.nn(output.view(100,-1))\n",
    "class CNN4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Conv2d(1,64,kernel_size=3, padding = 2),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(64,128,kernel_size=3, padding = 2),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(128,256,kernel_size=3, padding = 2),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(256,128,kernel_size=3, padding = 2),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.Conv2d(128,64,kernel_size=3, padding = 2),\n",
    "        nn.MaxPool2d((2,2), stride = 2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((2,2), stride = 2))\n",
    "        self.nn = nn.Sequential(nn.Linear(64,20,bias = True),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(20,10,bias = True))\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return self.nn(output.view(100,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce73f60c-877e-47b0-bdff-0e9bca9b1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay as cdm\n",
    "def test(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c06ae352-882a-4e51-a3c5-f29e1e7e0c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.3630\n",
      "Epoch [1/2], Step [200/600], Loss: 0.2628\n",
      "Epoch [1/2], Step [300/600], Loss: 0.2032\n",
      "Epoch [1/2], Step [400/600], Loss: 0.2468\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1985\n",
      "Epoch [1/2], Step [600/600], Loss: 0.2008\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1065\n",
      "Epoch [2/2], Step [200/600], Loss: 0.1316\n",
      "Epoch [2/2], Step [300/600], Loss: 0.1374\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0786\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1232\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0668\n",
      "Epoch [1/2], Step [100/600], Loss: 1.0370\n",
      "Epoch [1/2], Step [200/600], Loss: 0.5967\n",
      "Epoch [1/2], Step [300/600], Loss: 0.4454\n",
      "Epoch [1/2], Step [400/600], Loss: 0.3708\n",
      "Epoch [1/2], Step [500/600], Loss: 0.2206\n",
      "Epoch [1/2], Step [600/600], Loss: 0.2015\n",
      "Epoch [2/2], Step [100/600], Loss: 0.2083\n",
      "Epoch [2/2], Step [200/600], Loss: 0.2132\n",
      "Epoch [2/2], Step [300/600], Loss: 0.2109\n",
      "Epoch [2/2], Step [400/600], Loss: 0.1633\n",
      "Epoch [2/2], Step [500/600], Loss: 0.3045\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1585\n",
      "Epoch [1/2], Step [100/600], Loss: 0.2992\n",
      "Epoch [1/2], Step [200/600], Loss: 0.0267\n",
      "Epoch [1/2], Step [300/600], Loss: 0.0492\n",
      "Epoch [1/2], Step [400/600], Loss: 0.0440\n",
      "Epoch [1/2], Step [500/600], Loss: 0.0485\n",
      "Epoch [1/2], Step [600/600], Loss: 0.0760\n",
      "Epoch [2/2], Step [100/600], Loss: 0.0152\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0315\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0536\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0327\n",
      "Epoch [2/2], Step [500/600], Loss: 0.0727\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0369\n"
     ]
    }
   ],
   "source": [
    "m1 = CNN().to(device)\n",
    "m2 = CNN2().to(device)\n",
    "m3 = CNN3().to(device)\n",
    "m4 = CNN4().to(device)\n",
    "\n",
    "o1 = torch.optim.Adam(m1.parameters(), lr=learning_rate)\n",
    "o2 = torch.optim.Adam(m2.parameters(), lr=learning_rate)\n",
    "o3 = torch.optim.Adam(m3.parameters(), lr=learning_rate)\n",
    "o4 = torch.optim.Adam(m4.parameters(), lr=learning_rate)\n",
    "#trainModel(m1,2, train_loader, o1)\n",
    "trainModel(m2,2, train_loader, o2)\n",
    "trainModel(m3,2, train_loader, o3)\n",
    "trainModel(m4,2, train_loader, o4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d7364b0-97de-40bd-8663-7aeed0a182fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2a = test(m2,test_loader)\n",
    "m3a = test(m3,test_loader)\n",
    "m4a = test(m4,test_loader)\n",
    "m1a = test(model,test_loader)\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "m2p = count_parameters(m2)\n",
    "m3p = count_parameters(m3)\n",
    "m4p = count_parameters(m4)\n",
    "m1p = count_parameters(model)\n",
    "import numpy as np\n",
    "x = [m1p,m1p-m2p,m1p-m3p,m4p-m1p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df0bf492-37b8-40b3-85a5-143e3ce01762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.        ,  74.53237026,  93.34170016, 394.00259015])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "x / m1p * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ef949fb-71fc-4c37-bb12-620ba181fe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6b27169510>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.array([m1a, m2a, m3a, m4a])\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d40a8395-ff66-4f96-943b-b3f93185ac84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149798, 111648, 139824, 590208])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc063483-68ed-487a-b065-b6ae84b3c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.963 , 0.9725, 0.9538, 0.9856])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba293697-a532-49ea-97b9-4f8515bb8013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
